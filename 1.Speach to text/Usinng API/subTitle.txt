What's happening, guys? In this video, we're going to be building a real time language translation app using hugging face, transformers and Gradio. Let's take a deeper look as to what we'll be going through. So, in order to build up our real time web app, what we're going to be doing is installing Gradio. So this gives us our Python UI package. We're also to install Transformers. So we're going to be able to download a pre trained language translation model from Transformers. And it's all open source, so you don't need a credit card or anything. Then what we're going to do is translate text using that Transformers pipeline. So you'll be able to see that we can pass through a string and have that translated into a different language. And then we're going to wrap it all up and build a web app using Gradio. So we'll actually be able to pass through some text and have that translated as and when we need. Let's take a look as to how this is all going to work. So, first up, what we'll do is we'll install and import Pytorch and Transformers. So Pytorch is a key dependency for Transformers. Well, in this case, we're going to be using the Pytorch implementation. Then we're actually going to download the pre trained language translation model. So there's a whole heap of different language translation models. And I'll show you where to actually get each of those. So if you wanted to try out a different one, you definitely could. And then what we're going to do is we're going to wrap up that translation pipeline and actually pass it through to our web app inside of Gradio. So we'll actually be able to type something into our input box and have that translated and the output translated. Ready to do it? Let's get to it. All righty, guys, so in order to go on ahead and build our translation web app, there's going to be three things that we need to do. So first up, what we need to do is install our dependencies. And our main dependencies are really going to be Pytorch hugging face transformers and Gradio. So we'll go on ahead and install those, and I'll explain a little bit as to what each one of them is going to do. Then we're going to load up our translation pipeline. So there's a whole bunch of pipelines, specifically NLP pipelines, available via hugging face transformers. So I'll show you where to get a bunch of those. Specifically, if you wanted to translate different languages, you can do that as well. And then last but not least, well, that didn't come out right. And then last but not least, what we're going to go on ahead and do is create a gradio function and create a user interface that actually allows us to pass through some text and actually have that translated. So first things first, let's go on ahead and install our dependencies. Now, the first dependency that we're going to need is Pytorch. Now this is available from pytorch.org. And in order to actually go on ahead and install it, you just need to go to install. And then right down here there's a whole walkthrough that sort of gives you some steps that you can actually go through to install it. So first up, you just need to choose your Pytorch build. I'm going to choose the long term stable one, which is one eight one. Then I'm going to choose my operating system, which in this case is windows. Then we need to choose the package or the way that we want to install it. So I'm going to choose Pip. But again, you could choose Conda if you wanted to. We're going to be coding this up in Python, so we'll leave that the same. And then last but not least, I'm going to choose CuDa eleven one, because I've got a CUDa accelerated machine. If you don't have a GPU, that's perfectly fine. Don't stress, you can still use it without CUDA. Just hit cpu over here and you should be good to go. So what I'm going to do is I'm going to copy this and jump back into our notebook and I'm going to paste that there. Let's just make sure we zoomed in. All good. And then what we need to do is add an exclamation mark before this, drop the three and run that cell. And this is going to go on ahead and install Pytorch. So once that's installed, which it looks like it has, we should be good to go. So this is just a warning. So you're using an older version of Pip. That's just because I didn't upgrade Pip, but that's fine, you can ignore that if you get that error. So that is Pytorch now installed. So we've gone and installed it from the Pytorch repository. Let me make sure my head's not blocking this. Then the next thing that we need to go on ahead and do is install our other dependencies. So let's go on ahead and do this. Okay, so those are our other dependencies now installed. So that looks like it's all installed successfully. So what I've gone and done there is installed three different packages or upgraded three different packages. So I've written exclamation mark Pip, install transformers. And so Transformers is going to give us our translation pipeline. I'll talk a little bit more about this in a second. Then I've gone and installed IPY widgets. So if you're doing this for the first time and you're downloading the model for the first time, you need to have IPY widgets installed because it gives you the progress bar as you're downloading the model. So it's funnily enough if you don't have IPI widgets installed just because it can't show the progress, but it sort of fails if you try to install it. So make sure you install IPY widgets. And then we've gone and installed Gradio. So I don't actually have a link for Gradio up here. So Gradio is an awesome library that I've been doing a lot of work with lately that gives you a nice way to demonstrate and interact with your machine learning model. So we're going to interact with our Gradio UI in a sec. And then I've passed through upgrade. So this is particularly for IPI widgets. You can drop this if you're installing for the first time. But in this particular case, our full line is exclamation mark Pip, install transformers, IPI widgets, Gradio and then upgrade. Now the next thing that we need to do is actually import these into our notebook. So as of now, all we've gone ahead and done is install them. We need to go and import them as well. So let's do that. Okay, that is both of our dependencies now imported. So what I've gone and written there is import Gradio as GR. So you can see those there. And then I've written from Transformers import pipeline. So gradio is going to give us our user interface. So this is our UI library and pipeline is going to give us our transformers pipeline, right. So gradio allows us to build user interfaces like this. So we're going to be building one that's a little bit similar to this. So we'll actually be able to pass through some text and have our translation output as well. So pretty cool. But again, you can do a whole bunch of additional stuff. So if you wanted to do face segmentation, if you wanted to do something like actually having draggable uis, you can definitely do that as well. So our first line is import Gradio as GR, and then our second line is from transformers import pipeline. So if you've watched any of my previous hugging face transformers NLP videos, this will be kind of familiar to you. So hugging face is a great open source library, which is doing a lot of really powerful work in the NLP space at the moment. Now, they've actually got a whole bunch of pretrained models that you can actually leverage. You can definitely fine tune these. So if you wanted to use GPT-2 or GPT Neo, you can definitely do that through this as well. So what we're going to do in this particular case is use a pretrained pipeline. And I'll include a link to this in the description below. So if you want to take a look at this link, you definitely can. So you can see here that hugging face transformers actually has this thing called a translation pipeline. So we're actually going to be using that. So if I select translation pipeline, basically the way to actually load it is to pass through, or to use the pipeline class, which you can see there and pass through the model that we actually want to use. So in this particular case, the format is in translation, and then the language that we want to translate from, and then the language that we want to translate to. So in this particular case, say, for example, we're doing English to Dutch, it would be translation underscore en to de. So de being, sorry, not Dutch, German. So en to de would be English to german translation. That being said, there are a ton of models available out there. So if you actually go to huggingface co models, and if I go to the baseline link, this is an entire repository of every single NLP model that is available through hugging face. Now, the cool thing about this is that there is a huge open source community behind this. So if you wanted to go and contribute, you definitely could. In fact, the Graham former video, or the grand former model that I did a video on not too long ago is actually available through here as well. So this is Prithiraj Damodaran's model. So again, I nailed it. This time I actually had a chat. So there's actually that grammar correction model available there as well. Now, if we actually go and hit translation over this side, so you can see there's a whole bunch of different tasks we're interested in translation. Now, there are a whole bunch of different models actually available here. So say, for example, we wanted English to Hindi, I think en h n or hi. So you can see there's an English to Hindi model if we wanted to English to Chinese or Mandarin. So en CN, is there one there? There might not be. You can see there's a whole bunch of different models. So trying to think what would be the model for Chinese? It doesn't actually say, but again, you can see there's a bunch. So say, for example, I wanted English to French. En fr. There's one for French over here. There's Russian. There's a whole heap of different language models that are actually available through this. Now, in this particular case, we're going to be doing English to German. So what we now need to do is actually go on ahead and load up this pipeline. So let's go ahead and do this. Okay, so we've gone and written our pipeline loading line there. So what I've written, I've created a new variable called translation underscore pipeline, and this is going to be what actually holds our model. And then I've set that equal to pipeline and then translation en to de. So if you remember correctly, when we were taking a look at our documentation, the task identifier that we need to pass through is the fact that we want a translation pipeline, and then we need to pass through the language that we want to translate from and then the language that we want to translate to. So I've passed through en here, and I've passed through de here. So it's going to go from English to German. Now, if we go back over here, that is exactly what we've gone and done. Let's add a couple of extra lines so we can see this a little bit better. So we've written translation underscore pipeline equals pipeline, and then we've gone and set that equal to the language that we want to translate from and to. Now, if we wanted to, for example, translate something, so I can type in translation pipeline and pass through a sentence. So I love ice cream. And you can see that this is now translating our text. So what we're actually getting out of here is a list. And then inside of that, we've got a dictionary which has our translation text, and it actually gives us our translated sentence. So in this particular case, I'm not going to try to pronounce that because I don't do German well, actually, I will itch lieb ice cream. So, pretty close, right? So that's obviously converting our english sentence to German. And you can see it's relatively straightforward to get started with. You create your translation pipeline, then you go and pass through the string that you want to translate. Now what we're going to do is we're effectively going to wrap this translate, and if we wanted to actually get this text out here, right, so we can just pass through. Let's actually store this inside of a results variable. So we'll call it results. And then if we go to results, we can grab the first value out of that list. And then, because this is now stored as a dictionary. So if we take a look at our type, you can see it's a dictionary. So to get our value out of a dictionary, what do we need to do? Pass through the key. And in this case, our text is stored inside of a value called translation text, or it's stored against a key called translation text. So if we extract that out, that is our translated result. So you can see that basically in these three lines. So we're creating our translation pipeline. We're then passing through the text that we want to translate, and then we're actually extracting our result. So really quickly we're actually able to go and perform open source translation using hugging face transformers. But it doesn't end there. What we're now going to do is we're going to create a function to wrap up all of this, and we're going to create our user interface using gradient. So let's go ahead and do this. So what we'll do is we'll create a new function called translate. And we'll call it translate transformers. And then we're going to pass through. So this is going to be a new function. We need to pass through what we actually want to translate. So we'll call it from text. And then let's go ahead and wrap up this function. Okay, so that is our function now set up. Now, you'll note that I haven't actually included the loading of the pipeline in there, so I don't want to have to reload it every single time I run this. But if you were doing this in more of a production like instance, you'd probably grab this pipeline and include it inside of this function as well. So in a nutshell, what I've gone and written is def to define a new function. And I've written translate underscore transformers. So that's going to be the name of our function. And then I've passed through one variable which is from underscore text. So this is going to be the text that we actually pass through to our translate transformers function. And then these two lines here are exactly the same as what we had over here. So we're first up passing our from text to our translation pipeline, which we had from up there. And we're storing the results of that translation inside of a variable called results. Then what this function is going to go on ahead and do is return our extracted results. So we're going to grab the first value inside of our list. And then we're going to grab the key, which is translation, underscore text out of that resulting dictionary. So if we now go and run translate transformers and pass through. I love ice cream. You can see that now it's actually returning the translated result. So if we try this out another way and say my name is Nick. You can see it's now converting our text successfully. So it's returning. My name is Nick. Any Germans on the line, let me know what my pronunciation was like. So now there's one last thing that we actually need to do. So we need to wrap this up inside of a gradio function, or wrap this up inside of our gradio app. So let's go on ahead and do this. So we're first up going to create our interface. And then we're actually going to run our app. Okay, that is our Gradio interface now. Done. Now, it's pretty cool how quickly you can actually write this up. So in a single line, we're actually able to create a UI. Now, I haven't actually shown it to you yet. Our UI is actually built. Now all we need to do is launch it. So what we're actually going to do is let me actually break this down for you. So what I've gone and done is used the Gradio interface class. So if we take a look at GR interface, this is sort of like the main class to actually go on ahead and build your gradio models. So you can see that interfaces are created with Gradio using the Gradio interface function. And this is sort of like your big wrapper. And then to that, we've actually passed through a couple of key arguments or key keyword arguments. So we've passed through the function that we want to run. And in this case, the function that we're going to be running is our Translate transformers function. From up here, we've passed through the inputs, or what we want our inputs to look like. Say, if you wanted to pass through images, you could obviously not for translation. But maybe if you did like image captioning, you could do something along those lines. So in this particular case, we've passed through an input type of text box, which is GR inputs text box. And then we've gone and specified two keyword arguments there. So how many lines we want available inside of our little text box. So think about it as your input. And then you're going to have your output. So our input is going to be a text box, and our output is just going to be text, which is going to be our translated text. So in order to specify our input, I've just written Gr inputs text box, and then pass through how many lines we want inside of that text box. And then I've gone and set a placeholder, which is just going to say text to translate. Then I've gone and set our outputs equal to text. And again, these are all keyword parameters. So we've got a comma between each one of those. So let's take a look at the full line. So, interface equals gr interface in caps because it's a case we're importing. And then function, we're setting our function equal to translate transformers. We're setting our inputs equal to Gr inputs text box. And that's got two keyword parameters, which is lines equals to two and placeholder equals text to translate. You could change the number of lines and change the placeholder without any issues. And then we've gone and set our outputs equal to text. Now all that's left for us to do is actually run interface launch. And this will run our app. And you can see that is our translation app now running there. So if we actually go and test this out. So let's type in. My name is Nick. You can see it's now outputting our translated. So again, really, really quickly, we're actually able to build this up. So let's pass through a bunch more. So, my name is Nicholas. I like to write code and read ML Research papers. I don't really like reading ML research papers. They drive me insane. But anyway, besides the point. So there you go. So my name is Nicholas. I'm not going to pronounce the rest of that. Actually. Let's do it again. Germans on the line. Let me know how I did itch. Shribe gone. Code terrible. You can start to see that it's actually going and converting our english text to German out over here. Now if we go and hit this link over here, which says running locally at whatever that link is, this is actually going to open up your app inside of a separate tab. So again, if we try that in here, my name is Nick. You can see that's now outputting the results of that. My name is Nick. That's within my capabilities. I don't know if that bigger sentence was, what about I love pizza? And let me actually zoom in on this so you can see it a little bit better. How do we bring this up? There we go. All right, so let's zoom in. That's not actually working. Wait, there we go. That's better. So my name is Nick. I love pizza and beer. Itched Lieb. Pizza and beer. There we go. Not too bad. All right, so that gives us an idea of how we can actually go and build it. And that on that note, that about wraps it up. So we've gone and done a bunch of stuff. So we went and installed our dependencies. We went and loaded up our pipeline using hugging face transformers. I really wanted this to be like an end to end tutorial. Something simple that you can add to your resume or to your portfolio as you're going for jobs and as you're leveraging machine learning capabilities. And then last but not least, what we went and did is we created our gradio function and we also set up our interface down here. That note. That about wraps it up. Thanks so much for tuning in, guys. Hopefully enjoyed this video. If you did, be sure to give it a thumbs up. Hit subscribe and tick that bell and let me know if you've got any questions, comments or just queries in the comments below. I'm always happy to give you a handout. Thanks again for tuning in. Peace.