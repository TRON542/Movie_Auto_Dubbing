{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Audio To Segments </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_wav(input_path, output_folder, segment_length):\n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "    # Define the segment length in milliseconds\n",
    "    segment_length_ms = segment_length * 1000\n",
    "\n",
    "    # Calculate the number of segments\n",
    "    num_segments = len(audio) // segment_length_ms\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Split the WAV file into segments and save each segment\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = (i + 1) * segment_length_ms\n",
    "        segment = audio[start_time:end_time]\n",
    "\n",
    "        # Save the segment to the output folder\n",
    "        output_file = os.path.join(output_folder, f\"segment_{i + 1}.wav\")\n",
    "        segment.export(output_file, format=\"wav\")\n",
    "      \n",
    "\n",
    "    # Specify the path to the input MP3 file\n",
    "input_path = \"D:\\\\Capstone\\\\VoiceDatasets\\\\REAL\\\\musk-original.wav\"\n",
    "\n",
    "    # Specify the output folder for the segments\n",
    "last = input_path[52:-4] \n",
    "new_dir = os.path.join(r'D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\Original\\\\',last) \n",
    "os.makedirs(new_dir,exist_ok=True)\n",
    " \n",
    "output_folder = os.path.join('D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\Original\\\\',last)\n",
    "\n",
    "    # Specify the desired segment length in seconds (20-30 seconds)\n",
    "segment_length = 30\n",
    "\n",
    "    # Call the function to split the MP3 file\n",
    "#split_wav(input_path, output_folder, segment_length)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Target seperation from Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Capstone\\VoiceDatasets\\Output\\biden-original\\segment_2.wav\n"
     ]
    }
   ],
   "source": [
    "from spleeter.separator import Separator\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def separate_source_voice(input_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "    # Convert to stereo if needed\n",
    "    if audio.channels == 1:\n",
    "        audio = audio.set_channels(2)\n",
    "\n",
    "    # Save the stereo audio to a temporary file\n",
    "    temp_file = os.path.join(output_folder, \"temp_audio.wav\")\n",
    "    audio.export(temp_file, format=\"wav\")\n",
    "\n",
    "    # Use Spleeter for source separation\n",
    "    separator = Separator('spleeter:2stems')\n",
    "    separator.separate_to_file(temp_file, output_folder)\n",
    "\n",
    "    # Remove temporary file\n",
    "    os.remove(temp_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models\\\\2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Could not find trained model in model_dir: pretrained_models\\2stems, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Segment segment_20.wav processing completed!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# input path\n",
    "input_path = \"D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\biden-original\\\\segment_2.wav\"\n",
    "\n",
    "# Define the main directory containing original files\n",
    "original_files_dir = os.path.join('D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\Original\\\\', last, '')\n",
    "\n",
    "for segment_number in range(20, 21):\n",
    "    # Create the current directory path for the segment\n",
    "    segment_path = f'segment_{segment_number}.wav'\n",
    "    current_segment_dir = os.path.join(original_files_dir, segment_path)\n",
    "\n",
    "    # Set input and output paths\n",
    "    input_path = current_segment_dir\n",
    "    output_folder = 'D:\\\\Capstone\\\\VoiceDatasets\\\\Output'\n",
    "\n",
    "    # Perform source voice separation\n",
    "    separate_source_voice(input_path, output_folder)\n",
    "\n",
    "    # Renamed folder path for temporary audio\n",
    "    temp_audio_folder_path = os.path.join(r'D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\temp_audio\\\\', segment_path)\n",
    "\n",
    "    # Creating the final directory for noise-removed files\n",
    "    noise_removed_dir = os.path.join(r'D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\Noise removed\\\\', last)\n",
    "    os.makedirs(noise_removed_dir, exist_ok=True)\n",
    "\n",
    "    # Final path for the segment in the noise-removed directory\n",
    "    final_segment_path = os.path.join(noise_removed_dir, segment_path)\n",
    "\n",
    "    # Rename the vocals file\n",
    "    os.rename(r'D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\temp_audio\\\\vocals.wav', temp_audio_folder_path)\n",
    "\n",
    "    # Move the renamed folder to the final directory\n",
    "    shutil.move(temp_audio_folder_path, final_segment_path)\n",
    "\n",
    "    # Remove the temporary_audio folder\n",
    "    shutil.rmtree(r'D:\\\\Capstone\\\\VoiceDatasets\\\\Output\\\\temp_audio')\n",
    "\n",
    "    # Print completion message\n",
    "    print(f'Segment {segment_path} processing completed!')\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # Pause for 5 seconds\n",
    "    time.sleep(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
